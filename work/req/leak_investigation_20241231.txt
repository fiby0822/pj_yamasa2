調査日: 2024-12-31（想定）
調査者: Codex（データサイエンティスト）

概要:
work/vis_2024-12-31_3 実行時に観測された異常に高い精度は、学習前のプロダクト選別処理におけるターゲットリークが原因です。カスタムのプロダクトレベル学習スクリプトと共通の TimeSeriesPredictor いずれも、予測期間で実績値が正となる product/material_key を実績値そのもので判定し、該当するプロダクトのみを学習・評価対象として残します。これにより、評価対象の系列は「未来に需要があると既知」のものに限定され、評価指標が人工的に高くなっています。

主な証拠:
1. work/script/train_model_product_level.py:82-101 では、予測対象期間（file_date > train_end）で actual_value > 0 となる回数を数え、active_products_test を生成。この集合を使ってデータセットを絞り込み、さらに self.prediction_targets として評価対象に設定しています。
2. /home/ubuntu/yamasa/modules/models/train_predict.py:595-658 の TimeSeriesPredictor._filter_important_material_keys でも同じロジックを再実装。テスト期間の実績から mk_active_counts を計算し、actual_value > 0 が一定数以上の material_key のみを prediction_target_keys として返します。train_test_predict_time_split はこの leaked subset のみで予測と評価を行うため、非アクティブな系列は一切指標を悪化させません。
3. work/script/generate_features_product_level.py の特徴量生成は train/test 分割を順守しており、リークは検出されませんでした。異常は上記のプロダクト選別処理に限定されます。

影響評価:
- 評価指標（例: MAPE ≈ 7.4%）は、予測期間に需要が発生しない製品が除外されているため過小推定になります。
- モデルは「どの製品が予測期間で動くか」を事前に知っている状態と同等になり、実際のスパイクを正確に追従できたように見えます。
- 実運用では未来の需要発生フラグは得られないため、同様の精度は期待できません。

改善提案:
1. フィルタリングロジックから予測期間の実績値を排除し、train_end_date 以前の情報（直近の実績、ビジネスルールなど）または全製品を対象に学習・評価してください。
2. 必要に応じてプロダクト選別を行う場合でも、事前に利用可能なシグナル（train_end 以前の活動度、商品属性情報など）に限定し、未来実績を利用しないようにしてください。
3. 漏洩箇所を修正した後、検証を再実行して真の性能を把握してください。非アクティブな製品が戻ることで指標は低下する見込みです。
4. テスト期間データを使った判定が紛れ込まないよう、ユニットテストやアサーションなどで自動的に検知する仕組みを追加してください。
